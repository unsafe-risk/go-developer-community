---
title: "[GDC] Weekly Newsletter September 2nd"
datePublished: Sun Sep 08 2024 21:20:17 GMT+0000 (Coordinated Universal Time)
cuid: cm0u2vd4p000209jx8dw3cobh
slug: gdc-weekly-newsletter-september-2nd
tags: newsletter

---

# [GDC] Weekly Newsletter September 2nd

## Go 애플리케이션 성능 향상: 프로파일 기반 최적화 활용하기

- 소개
    * Go 컴파일러는 실행 시 어떤 코드가 자주 사용되는지 알 수 없기 때문에, 정적인 추측에 의존하여 최적화를 수행합니다. 이로 인해 실제 실행 환경에서 성능이 저하될 수 있습니다. 프로파일 기반 최적화(PGO)는 Go 컴파일러에게 애플리케이션 실행 프로파일을 제공하여 컴파일러가 더 정확한 최적화를 수행할 수 있도록 돕는 기법입니다.
    * 이 글에서는 PGO를 사용하여 Go 애플리케이션의 성능을 향상시키는 방법을 단계별로 설명합니다. Google Cloud의 Cloud Run 및 Cloud Profiler를 활용하여 PGO를 효과적으로 적용하는 방법도 함께 소개합니다.

- 요약
    * Go 1.21부터 지원되는 PGO는 컴파일러가 애플리케이션 실행 프로파일을 기반으로 최적화를 수행하여 실행 속도를 향상시키는 기법입니다.
    * PGO를 사용하려면 애플리케이션을 실행하여 프로파일 데이터를 수집한 후, 컴파일 시 이 데이터를 사용해야 합니다.
    * Google Cloud의 Cloud Run은 PGO를 적용하기 쉬운 환경을 제공하며, Cloud Profiler는 프로파일 데이터 수집을 자동화합니다.
    * PGO를 적용하면 CPU 사용량 감소와 컨테이너 실행 시간 단축과 같은 성능 향상을 기대할 수 있습니다.

- 레퍼런스
    * [Read more](https://cloud.google.com/blog/products/application-development/using-profile-guided-optimization-for-your-go-apps)

## 파일 쓰기 후 즉시 닫기: 왜 중요할까?

- 소개
    * Go 프로그래머라면 파일을 열고 <code>Close()</code> 메서드를 <code>defer</code>하는 것을 익숙하게 사용할 것입니다. 하지만 쓰기 가능한 파일의 경우 이러한 관행은 예상치 못한 버그를 유발할 수 있습니다.
    * 이 글에서는 왜 쓰기 가능한 파일을 즉시 닫아야 하는지, 그리고 <code>defer</code>를 사용하지 않는 것이 더 나은 선택인 이유를 자세히 알아봅니다.

- 요약
    * 파일을 닫는 것은 자원을 해제하고 데이터 손실을 방지하는 중요한 작업입니다. 
    * 쓰기 가능한 파일에 대한 <code>Close()</code> 메서드는 오류를 반환할 수 있으며, <code>defer</code>를 사용하면 이러한 오류를 무시하게 됩니다.
    * 파일을 즉시 닫는 것이 더 안전하고 명확한 방법이며, Go의 <code>with</code> 문을 활용하면 코드를 더 간결하게 작성할 수 있습니다.

- 레퍼런스
    * [Read more](https://www.joeshaw.org/dont-defer-close-on-writable-files/)

## Go로 만든 AV 라이브러리, astiav

- 소개
    * Go 개발자라면 AV 파일 처리에 어려움을 겪었을 거예요. astiav는 Go로 만들어진 AV 라이브러리로, 다양한 형식의 AV 파일을 쉽게 처리할 수 있도록 도와줍니다. 
    * 이 라이브러리를 사용하면 AV 파일의 정보를 얻거나, 변환, 스트리밍 등 다양한 작업을 간편하게 수행할 수 있습니다. 

- 요약
    * astiav는 Go 언어로 작성된 AV 라이브러리로, ffmpeg를 기반으로 합니다. 
    * 다양한 AV 파일 형식을 지원하며, 파일 정보를 가져오고, 파일을 변환하거나, 스트리밍할 수 있습니다. 
    * 상세한 문서와 예제 코드를 제공하여 Go 개발자가 AV 파일을 효율적으로 처리할 수 있도록 돕습니다. 
    * ffmpeg의 강력한 기능을 Go 환경에서 활용할 수 있어 편리합니다.

- 레퍼런스
    * [Read more](https://github.com/asticode/go-astiav) 

## ReflectSelect를 이용한 임의 채널 처리

- 소개
    * Go에서 채널을 다루는 데 유용한 라이브러리인 ReflectSelect는, 다양한 종류의 채널을 하나의 인터페이스를 통해 처리할 수 있도록 도와줍니다. 특히 동적으로 생성된 채널 목록에서 임의의 채널을 선택해야 할 때 유용합니다.
    * 이 글에서는 ReflectSelect의 활용법을 이해하고, 여러분의 Go 코드를 더욱 효율적으로 만들 수 있는 방법을 배우세요.

- 요약
    * Go의 `select` 문은 여러 채널 작업을 동시에 기다리고, 데이터가 도착한 채널을 선택할 수 있지만, 고정된 수의 채널만 처리 가능합니다.
    * `reflect.Select` 함수는 임의의 수의 채널을 처리하는 데 사용할 수 있습니다. `reflect.SelectCase` 구조체를 사용하여 각 채널에 대한 처리 방식을 정의하고, `Select` 함수를 통해 데이터가 도착한 채널을 선택합니다.
    * ReflectSelect는 여러 채널을 동시에 관리하고 데이터를 효율적으로 처리해야 하는 상황에서 유용하며, 복잡한 코드를 간결하게 작성할 수 있도록 지원합니다.

- 레퍼런스
    * [Read more](https://dev.to/hgsgtk/handling-with-arbitrary-channels-by-reflectselect-4d5g)

## retry-go: Go에서 재시도 메커니즘을 간편하게 구현하는 라이브러리

- 소개
    * retry-go는 Go에서 재시도 패턴을 쉽고 효율적으로 구현할 수 있도록 도와주는 간단한 라이브러리입니다. 
    * 네트워크 오류나 시스템 오류 등 예상치 못한 문제로 인해 함수 실행이 실패하는 경우, retry-go를 사용하여 자동으로 재시도를 수행하고, 안정적인 시스템을 구축할 수 있습니다.

- 요약
    * retry-go는 함수를 재시도할 횟수, 재시도 간격, 최대 지연 시간, 재시도 시도 간의 텀 등을 설정하여 다양한 재시도 전략을 구현할 수 있도록 지원합니다.
    * 사용자 정의 함수를 통해 재시도 여부를 결정할 수 있으며, 재시도 횟수, 지연 시간, 지연 유형 등을 설정할 수 있는 다양한 옵션을 제공합니다.
    * retry-go는 <code>Do</code>, <code>DoWithData</code> 등의 간편한 API를 제공하여 재시도 로직을 쉽게 구현할 수 있도록 돕습니다.
    * 다양한 오류 유형에 대한 재시도 처리를 지원하며, 필요에 따라 특정 오류만 재시도하도록 필터링할 수 있습니다.
    * 테스트를 거쳤으며, 확장성이 뛰어나 여러 프로젝트에 활용하기 용이합니다.

- 레퍼런스
    * [Read more](https://github.com/avast/retry-go) 

## Go 언어로 자바스크립트 지옥에서 탈출: Everything in Go

- 소개
    * 프론트엔드 프레임워크의 광풍 속에서 자바스크립트 지옥에서 벗어나 Go 언어를 사용하여 모든 것을 개발하는 더 나은 세상을 소개합니다. 이 글은 Go 언어, Templ, HTMX, AlpineJS, PocketBase 그리고 TailwindCSS를 결합한 웹 개발 스택을 소개합니다. 
    * 복잡한 자바스크립트/타입스크립트 코드 대신 간결하고 효율적인 Go 언어를 사용하여 웹 애플리케이션을 개발하고 싶은 개발자들에게 유용한 정보를 제공합니다.

- 요약
    * 이 글은 개인 웹사이트를 Go 언어, Templ, HTMX, AlpineJS, PocketBase, TailwindCSS를 사용하여 새롭게 구축한 경험을 공유합니다. 
    * Go 언어를 기반으로 HTMX를 사용하여 HTML 자체로 웹 애플리케이션의 상호 작용을 처리하고, PocketBase를 사용하여 데이터 관리 및 백엔드 로직을 구축하며, Templ을 통해 Go 코드에서 HTML 템플릿을 생성합니다. 
    * 또한, TailwindCSS를 사용하여 디자인을 간편하게 구현하고 AlpineJS를 활용하여 HTMX와 함께 작동하는 작은 클라이언트 사이드 상호 작용을 추가합니다. 
    * 이 스택은 복잡한 프론트엔드 프레임워크 없이도 효율적인 웹 개발이 가능하다는 것을 보여줍니다.

- 레퍼런스
    * [Read more](https://oblivion.keyruu.de/Web-Development/Everything-in-Go) 

## Grol: Go REPL 오픈 언어

- 소개
    * Grol은 Go로 작성된 REPL(Read-Eval-Print Loop) 기반의 오픈 소스 프로그래밍 언어입니다. 
    * Grol은 간단하고 직관적인 구문을 제공하여 초보자도 쉽게 배우고 사용할 수 있으며, 강력한 기능을 통해 다양한 작업을 수행할 수 있습니다.

- 요약
    * Grol은 Go 언어를 기반으로 하지만, 더욱 간결하고 사용자 친화적인 구문을 제공합니다. 
    * 함수, 람다, 클로저, 재귀 함수 등을 지원하며, 배열, 정렬된 맵, 맵 키에 대한 간편한 액세스 기능을 제공합니다.
    * print, log, 매크로 등을 지원하며, 자동 메모이제이션 기능을 제공합니다.
    * Go 함수를 Grol에 확장하여 사용할 수 있으며, 가변 인자 함수를 지원합니다.
    * info 객체를 사용하여 사용 가능한 함수, 키워드, 연산자 등을 확인할 수 있습니다.
    * save() 및 load() 함수를 사용하여 현재 상태를 저장하고 불러올 수 있습니다.
    * 다양한 예제 파일을 제공하며, 웹 브라우저에서 실행할 수 있는 Wasm 버전도 제공합니다.

- 레퍼런스
    * [Read more](https://github.com/grol-io/grol) 

## 13년차 개발자가 말하는 Go 언어로 HTTP 서비스 작성하기

- 소개
    * 13년 이상의 개발 경력을 가진 Grafana Labs의 수석 엔지니어이자 Go Time 팟캐스트 진행자인 Mat Ryer가 Go 언어로 HTTP 서비스를 작성하면서 얻은 경험과 노하우를 공유합니다. 
    * Go 언어를 사용하여 HTTP 서비스를 구축하는 방법에 대한 실질적인 조언과 함께 다양한 예시 코드를 통해 Go 언어의 장점을 활용하여 효율적이고 안정적인 서비스를 만드는 방법을 보여줍니다. 

- 요약
    * 13년 동안 다양한 언어와 프레임워크를 경험하며 얻은 지식을 바탕으로 Go 언어로 HTTP 서비스를 작성하는 방법에 대한 저자의 생각을 공유합니다.
    * Go 언어의 강력한 기능과 쉬운 사용성을 활용하여 효율적인 HTTP 서비스를 구축하는 방법을 설명하며, 특히 Go 언어의 내장 패키지를 활용하여 HTTP 서버를 구축하는 방법과 다양한 라이브러리와 프레임워크를 소개합니다. 
    * 또한, HTTP 요청과 응답을 처리하는 방법, HTTP 라우팅 구현, 에러 처리 및 로그 기록 방법 등을 실제 프로젝트에 적용할 수 있는 예시 코드와 함께 자세히 다룹니다. 
    * 마지막으로 Go 언어로 HTTP 서비스를 개발하는 데 도움이 되는 몇 가지 팁과 주의 사항을 제시합니다.

- 레퍼런스
    * [Read more](https://grafana.com/blog/2024/02/09/how-i-write-http-services-in-go-after-13-years/) 

## Go 1.23 이터레이터 디자인: 왜 사람들은 화가 났을까?

- 소개
    * Go 1.23에서 도입될 예정인 새로운 이터레이터 디자인에 대한 논란과 그 배경을 살펴봅니다. 
    * 이 글은 Go 언어의 철학, 이터레이터 디자인의 장단점, 그리고 다른 프로그래밍 언어에서 이터레이터를 구현하는 방식을 비교 분석합니다. 

- 요약
    * Go 1.23에서 도입되는 이터레이터 디자인은 함수형 프로그래밍 스타일을 강조하며, 기존의 Go 언어가 추구해온 명령형 프로그래밍 방식과 충돌한다는 비판을 받고 있습니다.
    * 이 글에서는 이터레이터 디자인의 장점과 단점을 분석하고, Go 언어의 철학과의 부합성을 논의합니다. 
    * 또한, Odin과 C++ 등 다른 언어에서 이터레이터를 구현하는 방식을 비교하여 Go 1.23 이터레이터 디자인의 장단점을 더 자세히 살펴봅니다. 

- 레퍼런스
    * [Read more](https://www.gingerbill.org/article/2024/06/17/go-iterator-design/) 

## 마로토: 자바스크립트로 PDF 생성하기

- 소개
    * 마로토는 Bootstrap에서 영감을 받아 gofpdf를 사용하는 빠르고 간단한 자바스크립트 기반 PDF 생성 라이브러리입니다. 복잡한 설정 없이 간단한 API를 사용하여 웹 애플리케이션에서 PDF 문서를 쉽게 생성할 수 있습니다.
    * 이미지, 텍스트, 테이블, 폼 등을 포함하여 다양한 컨텐츠를 PDF 문서에 추가하고, CSS 스타일을 적용하여 문서 디자인을 커스터마이징할 수 있습니다. 마로토는 웹 애플리케이션에서 PDF 문서 생성 기능을 구현해야 하는 개발자에게 유용한 도구입니다.

- 요약
    * 마로토는 자바스크립트로 PDF 문서를 생성하는 라이브러리입니다.
    * Bootstrap의 레이아웃 시스템과 유사한 구조를 사용하여 컨텐츠를 쉽게 배치할 수 있습니다.
    * gofpdf를 기반으로 하여 빠르고 효율적인 PDF 문서 생성을 지원합니다.
    * 이미지, 텍스트, 테이블, 폼 등 다양한 컨텐츠를 지원하고, CSS 스타일을 적용하여 디자인을 커스터마이징할 수 있습니다.
    * 마로토는 오픈 소스 프로젝트로 GitHub에서 소스 코드를 확인하고 사용할 수 있습니다.

- 레퍼런스
    * [Read more](https://github.com/johnfercher/maroto) 

## Go 코드 커버리지 향상을 위한 Covdata 활용

- 소개
    * Go 프로그램이나 통합 테스트를 실행하면 일반적으로 `GOCOVERDIR` 환경 변수에 지정된 디렉토리에 원시 커버리지 파일이 생성됩니다. 이러한 파일은 테스트 중에 코드의 어떤 부분이 실행되었는지에 대한 귀중한 데이터를 포함하고 있어 코드의 효율성과 안정성을 파악하는 데 도움이 됩니다. 하지만 이러한 원시 파일을 탐색하여 실행 가능한 통찰력을 얻는 것은 많은 개발자에게 어렵고 불분명할 수 있습니다.
    * 이때 `covdata`가 등장합니다. `covdata`는 Go의 원시 커버리지 파일 분석의 복잡성을 해결하기 위해 특별히 설계된 강력한 도구입니다. `covdata`는 각각 복잡한 데이터 세트를 더 쉽게 이해할 수 있는 형식으로 변환하도록 맞춤화된 일련의 하위 명령을 제공하여 프로세스를 간소화합니다. 커버리지 지표를 요약하는 간단한 텍스트 형식의 출력을 생성하든, 코드 커버리지에 대한 자세한 행 단위 보기를 제공하는 정교한 HTML 파일을 생성하든 `covdata`는 사용자의 요구를 충족할 수 있습니다.

- 요약
    * `covdata`는 Go 코드 커버리지를 측정하고 시각화하는 도구입니다. 
    * `covdata`를 사용하면 코드 커버리지 보고서를 생성하고 HTML 형식으로 시각화하여 테스트되지 않은 코드를 쉽게 파악할 수 있습니다.
    * `covdata`는 Go 테스트 커버리지 도구인 `go test -coverprofile`과 함께 사용하여 코드 커버리지 정보를 수집합니다. 
    * `covdata`는 다양한 커버리지 측정 방법을 제공하며 사용자 정의 옵션을 통해 보고서를 맞춤 설정할 수 있습니다.
    * `covdata`를 사용하면 Go 코드의 테스트 커버리지를 향상시키고 코드 품질을 개선할 수 있습니다.

- 레퍼런스
    * [Read more](https://devdojo.com/keploy/how-to-use-covdata-for-better-code-coverage-in-go) 

## ChartDB: 싱글 쿼리로 데이터베이스 다이어그램을 시각화하고 디자인하는 오픈소스 도구

- 소개
    * ChartDB는 데이터베이스 다이어그램을 쉽게 시각화하고 디자인할 수 있도록 도와주는 무료 오픈소스 도구입니다. 
    * 단 하나의 "스마트 쿼리"를 실행하여 데이터베이스 스키마를 JSON 형식으로 가져와 시각화할 수 있으며, 다이어그램을 사용자 정의하고 SQL 스크립트를 내보낼 수 있습니다. 

- 요약
    * ChartDB는 웹 기반 데이터베이스 다이어그램 편집기로, 설치가 필요 없고 데이터베이스 비밀번호도 필요하지 않습니다.
    * 단일 쿼리를 실행하여 데이터베이스 스키마를 JSON 형식으로 가져와 시각화할 수 있습니다.
    * 다이어그램을 사용자 정의하고 SQL 스크립트를 다양한 데이터베이스 언어로 내보낼 수 있습니다.
    * PostgreSQL, MySQL, SQL Server, MariaDB, SQLite 등 다양한 데이터베이스를 지원합니다.
    * 오픈소스 프로젝트로, 커뮤니티 기반의 지속적인 개발과 지원을 받고 있습니다.

- 레퍼런스
    * [Read more](https://github.com/chartdb/chartdb) 

## GoFakeIt을 사용하여 가짜 데이터 생성하기

- 소개
    * GoFakeIt은 Go 개발자를 위한 가짜 데이터 생성 라이브러리입니다.  테스트 데이터를 생성하거나 데이터베이스를 채우는 데 유용하게 사용할 수 있습니다. 이 라이브러리는 이름, 주소, 이메일 주소, 전화번호, 날짜, 시간, UUID 등 다양한 유형의 가짜 데이터를 생성하는 데 도움을 줄 수 있습니다.
    * 이 글에서는 GoFakeIt을 사용하여 가짜 데이터를 생성하는 방법과 다양한 사용 예시를 살펴봅니다.

- 요약
    * GoFakeIt은 Go에서 다양한 유형의 가짜 데이터를 생성하기 위한 라이브러리입니다.
    * 이름, 주소, 전화번호, 이메일 주소, 날짜, 시간, UUID 등을 포함한 여러 종류의 데이터를 생성할 수 있습니다.
    * GoFakeIt은 사용하기 쉽습니다. `gofakeit.New(0)` 함수를 사용하여 GoFakeIt 인스턴스를 생성하고, `Int()`, `String()`, `Email()`, `Address()`, `Date()`, `UUID()`와 같은 함수를 사용하여 가짜 데이터를 생성할 수 있습니다.
    * GoFakeIt은 테스트 데이터 생성, 데이터베이스 채우기, 시뮬레이션 등 다양한 용도로 사용됩니다.

- 추천
    * GoFakeIt은 테스트 데이터 생성이나 데이터베이스를 채우는 데 유용합니다. Go 프로젝트에서 가짜 데이터가 필요하다면 GoFakeIt을 사용해 보세요!

- 레퍼런스
    * [Read more](https://dev.to/ankitmalikg/golang-generate-fake-data-with-gofakeit-23gj?utm_source=dormosheio&utm_campaign=dormosheio)

## Go 언어로 OAuth2 시작하기: 간단한 Google 로그인 구현 가이드

- 소개
    * 이 글은 Go 언어를 사용하여 웹 애플리케이션에 Google 로그인 기능을 구현하는 방법을 보여주는 실용적인 가이드입니다. OAuth2를 사용하여 Google 계정을 통해 사용자를 인증하는 방법을 단계별로 설명하며, 실제 코드 예제를 통해 이해를 돕습니다.
    * OAuth2는 사용자의 계정 정보를 직접 공유하지 않고도 다른 웹 애플리케이션에 대한 액세스 권한을 부여할 수 있는 표준 프로토콜입니다. 이 글에서는 Go 언어의 `golang.org/x/oauth2` 패키지를 활용하여 Google OAuth2 인증을 구현하는 방법을 알려드립니다.

- 요약
    * Google Cloud Platform에서 OAuth2 자격 증명을 생성하고, `golang.org/x/oauth2` 패키지를 사용하여 Go 애플리케이션에서 Google 로그인을 설정하는 방법을 설명합니다.
    * 인증 흐름을 구현하는 방법, 액세스 토큰 획득 및 사용, 사용자 정보 가져오기 등을 다룹니다.
    * 이 글을 통해 Go 언어로 간단하고 안전한 Google 로그인을 구현하여 사용자에게 편리한 인증 경험을 제공할 수 있습니다.

- 레퍼런스
    * [Read more](https://medium.com/@pliutau/getting-started-with-oauth2-in-go-2c9fae55d187) 

## Go에서 구조체와 인터페이스에 제네릭을 사용하는 방법

- 소개
    * Go 1.18 버전부터 제네릭을 지원하여 특정 타입에 의존하지 않는 코드를 작성할 수 있게 되었습니다. 이를 통해 함수와 타입을 다양한 타입에 적용하여 코드 재사용성을 높일 수 있습니다.
    * 이 글에서는 Go에서 제네릭을 구조체와 인터페이스에 적용하는 방법을 자세히 살펴보고, 실제 사용 예시를 통해 이해를 돕고자 합니다.

- 요약
    * Go에서 제네릭은 `[T any]`와 같은 형식으로 타입 매개변수를 사용하여 정의됩니다. 
    * 제네릭을 구조체에 적용하면, 타입 매개변수를 통해 다양한 타입의 데이터를 저장하고 처리할 수 있는 유연한 구조체를 만들 수 있습니다.
    * 제네릭 인터페이스는 `type Getter[T any] interface { Get() T }`와 같이 정의되며, 특정 타입에 의존하지 않는 일반적인 메서드를 정의할 수 있습니다. 
    * 제네릭을 통해 코드의 재사용성을 높이고, 다양한 타입의 데이터를 처리하는 코드를 효율적으로 작성할 수 있습니다. 

- 레퍼런스
    * [Read more](https://medium.com/@samix.ys/how-to-use-generics-in-a-structs-and-interfaces-in-golang-69bd8dcbeb2d) 

## Redis를 이용한 분산 락 구현: 다중 서버 환경에서 데이터 동시 접근 문제 해결

- 소개
    * 여러 서버에서 동시에 데이터를 수정해야 할 때 발생하는 경쟁 조건 문제를 해결하는 방법 중 하나로 Redis를 이용한 분산 락 구현에 대한 자세한 내용을 다룹니다. 
    * 이 글에서는 Redis의 SETNX, EXPIRE 명령어를 사용하여 락을 생성하고 관리하는 기본적인 방법부터 Redlock 알고리즘을 활용한 더욱 안정적인 분산 락 구현까지 다양한 측면을 살펴봅니다.

- 요약
    * 분산 락은 다중 서버 환경에서 발생하는 경쟁 조건 문제를 해결하기 위해 사용됩니다.
    * Redis의 SETNX, EXPIRE 명령어를 조합하여 락을 생성하고 만료시키는 기본적인 방법을 설명합니다.
    * 단일 Redis 인스턴스의 문제점을 지적하고, 여러 Redis 인스턴스를 사용하는 Redlock 알고리즘을 소개합니다.
    * Redlock 알고리즘은 락 획득 및 해제를 여러 Redis 인스턴스에 걸쳐 동시에 처리하여 장애에 대한 내성을 높입니다.
    * 분산 락 구현 시 발생할 수 있는 문제점과 주의 사항, 그리고 Redlock 알고리즘의 단점 등을 분석합니다.

- 레퍼런스
    * [Read more](https://dev.to/ssd/how-to-implement-a-distributed-lock-using-redis-he) 

## PostgreSQL에서 Parquet 형식의 S3에 물질화 뷰를 사용하는 방법: ETL 없는 데이터 파이프라인 구축

- 소개
    * 이 글에서는 IoT 애플리케이션에서 S3에 저장된 Parquet, JSON, CSV 파일을 PostgreSQL에 물질화 뷰로 가져오는 방법을 소개합니다. 
    * 이 워크플로우는 객체 저장소에서 PostgreSQL로 데이터를 쉽게 파이프라인하여 다양한 사용 사례에 활용할 수 있습니다. 

- 요약
    * IoT 애플리케이션은 종종 다양한 시스템을 사용하는 데이터 파이프라인을 필요로 합니다. 
    * Crunchy Bridge for Analytics는 DuckDB를 통합하여 빠른 분석을 위한 관리형 PostgreSQL 솔루션을 제공합니다.
    * S3의 Parquet 파일을 외래 테이블을 통해 PostgreSQL에서 효율적으로 쿼리할 수 있습니다.
    * 물질화 뷰를 사용하여 데이터를 사전 집계하고 쿼리 성능을 향상시킬 수 있습니다.
    * PostgreSQL의 cron.schedule 기능을 활용하여 물질화 뷰를 자동으로 새로 고칠 수 있습니다.

- 레퍼런스
    * [Read more](https://www.crunchydata.com/blog/postgres-materialized-views-from-parquet-in-s3-with-zero-etl)

## 트위터, 실시간으로 40억 건의 이벤트를 처리하는 방법: 람다에서 카파로

- 소개
    * 트위터는 매일 40억 건 이상의 이벤트를 실시간으로 처리하는 거대 기술 기업입니다. 이 글에서는 트위터가 방대한 데이터를 실시간으로 처리하고 빠르고 안정적인 서비스를 제공하는 방법을 살펴봅니다. 특히, 트위터의 아키텍처 변화와 기술적 노하우를 통해 대규모 데이터 처리 시스템 설계에 대한 통찰력을 얻을 수 있습니다.
    * 트위터의 과거 람다 아키텍처에서 현재 카파 아키텍처로의 전환 과정과 그 이유, 그리고 새로운 아키텍처가 제공하는 장점을 자세히 알아봅니다.

- 요약
    * 트위터는 초기에 람다 아키텍처를 사용하여 배치 처리와 실시간 스트림 처리를 분리하여 데이터를 처리했습니다. 하지만 대규모 데이터 처리의 어려움으로 인해 데이터 손실과 정확성 저하, 높은 시스템 지연 시간 등의 문제점을 겪었습니다.
    * 이러한 문제점을 해결하기 위해 트위터는 카파 아키텍처로 전환했습니다. 카파 아키텍처는 단일 실시간 처리 파이프라인을 사용하여 데이터를 처리하며, Google Cloud Platform (GCP)의 Pub/Sub, Dataflow, BigTable 등을 활용합니다.
    * 새로운 카파 아키텍처는 기존 람다 아키텍처에 비해 처리 속도와 정확성이 크게 향상되었습니다. 또한, 시스템 지연 시간이 줄어들고, 배치 처리 파이프라인을 없애 비용 절감 효과도 얻었습니다.

- 레퍼런스
    * [Read more](https://blog.det.life/how-twitter-processes-4-billion-events-in-real-time-daily-942db8f7d7b5) 

## Reddit의 초당 10만 건 메타데이터 요청 처리: Postgres 활용

- 소개
    * Reddit은 인터넷의 프론트 페이지와 같으며 수십억 개의 게시물을 호스팅합니다. 이러한 게시물 중 상당수는 이미지, 비디오, GIF 등의 미디어 콘텐츠를 포함합니다. 미디어 콘텐츠는 일반적으로 객체 저장소에 저장되지만, 메타데이터는 별도로 저장됩니다. 예를 들어 비디오의 경우 썸네일 URL, 재생 URL, 비트 전송률, 다양한 해상도 등의 정보를 저장해야 합니다.
    * 이 글에서는 Reddit이 이러한 메타데이터를 효율적으로 처리하기 위해 Postgres를 활용하여 구축한 시스템에 대해 자세히 알아봅니다.

- 요약
    * Reddit은 사용자 프로필, 게시물, 댓글 등의 메타데이터를 빠르게 제공하기 위해 Postgres 데이터베이스를 사용하여 메타데이터 저장소를 구축했습니다. 
    * 시스템은 초당 10만 건 이상의 요청을 처리하며 50ms 미만의 낮은 지연 시간을 유지합니다.
    * 데이터 마이그레이션을 위해 기존 데이터베이스에서 새 Postgres 데이터베이스로 데이터를 복사하는 동시에 서비스를 중단하지 않고 운영을 계속 진행하는 전략을 사용했습니다.
    * 또한, 데이터를 효율적으로 저장하고 관리하기 위해 Postgres의 파티셔닝 기능을 활용합니다.

- 레퍼런스
    * [Read more](https://newsletter.systemdesigncodex.com/p/how-reddit-serves-100k-metadata-requests) 

## 넷플릭스, 2억 3천 8백만 회원 관리하는 비결은?

- 소개
    * 넷플릭스는 전 세계 2억 3천 8백만 명이 넘는 회원을 보유한 거대 스트리밍 서비스입니다. 이 글에서는 넷플릭스가 이렇게 많은 회원을 효율적으로 관리하고 끊김 없는 서비스를 제공하는 비결, 즉 넷플릭스의 회원 관리 시스템 아키텍처와 운영 전략에 대해 알아봅니다.
    * 특히 넷플릭스의 규모와 복잡성을 고려했을 때, 그들의 시스템 아키텍처는 흥미로운 학습 대상입니다. 이 글에서는 넷플릭스가 어떻게 대규모 사용자를 효율적으로 관리하고, 서비스 안정성을 유지하는지 자세히 알아봅니다.

- 요약
    * 넷플릭스는 마이크로서비스 아키텍처를 기반으로 다양한 서비스를 독립적으로 운영합니다. 이를 통해 각 서비스는 독립적으로 개발 및 배포될 수 있으며, 유연성과 확장성을 높입니다.
    * 넷플릭스는 AWS와 같은 클라우드 기반 인프라를 활용하여 급증하는 사용자 트래픽에 대응합니다. 클라우드 플랫폼은 넷플릭스가 필요에 따라 컴퓨팅 리소스를 탄력적으로 확장할 수 있도록 지원합니다.
    * 넷플릭스는 자동화된 배포 및 모니터링 시스템을 통해 지속적인 서비스 개선과 안정성 유지를 추구합니다. 이를 통해 개발 속도를 높이고 문제 발생 시 신속한 대응을 가능하게 합니다.
    * 넷플릭스는 A/B 테스트를 통해 새로운 기능을 점진적으로 도입하고 사용자 피드백을 수집합니다. 이는 서비스 개선 및 사용자 만족도 향상을 도모합니다.
    * 넷플릭스는 오픈소스 기술을 적극 활용하고 커뮤니티에 기여합니다. 이는 넷플릭스가 기술 발전에 참여하고 다른 개발자들과 협력할 수 있도록 돕습니다. 

- 레퍼런스
    * [Read more](https://blog.bytebytego.com/p/how-netflix-manages-238-million-memberships) 

## URL 단축 서비스 디자인하기

- 소개
    * 긴 URL을 짧고 기억하기 쉬운 고유한 URL로 변환하여 사용자 편의성을 높이는 URL 단축 서비스 디자인 방법에 대한 글입니다. 이 글은 수백만 개의 URL을 처리하고 빠른 리디렉션을 제공하며 고가용성을 보장하는 확장 가능하고 효율적인 URL 단축 서비스 디자인을 위한 단계별 안내를 제공합니다. URL 단축 서비스의 작동 원리와 구현에 필요한 기술들을 자세히 알아보고, 실제 서비스 개발에 적용할 수 있는 지식을 얻을 수 있습니다.
    * 이 글에서는 URL 단축 서비스의 기본적인 개념부터 실제 구현에 필요한 코드 예제까지 제공하여 URL 단축 서비스 디자인을 처음 접하는 개발자도 쉽게 이해할 수 있도록 돕습니다. 

- 요약
    * URL 단축 서비스는 긴 URL을 짧은 URL로 변환하여 사용자 경험을 향상시키고 링크 공유 및 트래픽 분석을 용이하게 합니다. 
    * 짧고 고유한 단축 URL을 생성하기 위해 난수 생성, 해시 함수 및 Base62 인코딩과 같은 다양한 알고리즘이 사용됩니다.
    * 데이터베이스 설계는 단축 URL과 원본 URL 간의 매핑 정보를 효율적으로 저장하고 관리하기 위한 중요한 요소입니다.
    * 서비스의 안정성과 성능을 확보하기 위해 리디렉션 서비스, 캐싱, 샤딩, 복제 및 장애 복구와 같은 다양한 기술들이 필요합니다.
    * URL 유효성 검사, 사용자 지정 별칭, 링크 만료 및 분석 서비스와 같은 추가적인 기능을 고려하여 서비스의 기능성을 확장할 수 있습니다.

- 레퍼런스
    * [Read more](https://blog.algomaster.io/p/design-a-url-shortener)

## Cassandra를 이용한 시계열 데이터 최적화: 실제 적용 사례와 학습

- 소개
    * 그루폰은 사용자들이 할인된 가격으로 다양한 상품과 서비스를 발견하고 구매할 수 있도록 모바일 및 온라인 마켓플레이스를 제공하는 회사입니다. 그루폰은 프로모션 코드 알림에 대한 기능을 구현하는 과정에서 Cassandra를 이용하여 시계열 데이터를 저장하고 처리하는 방법에 대한 다양한 접근 방식을 시도하고, 최적의 솔루션을 찾아내기 위해 노력했습니다. 
    * 이 글에서는 Cassandra를 사용하여 시계열 데이터를 효율적으로 저장하고 관리하는 방법에 대한 실제 적용 사례와 함께, 개발자가 직면할 수 있는 문제점과 해결 방안에 대한 심층적인 분석을 제공합니다. Cassandra를 활용한 시계열 데이터 저장 및 처리에 관심 있는 개발자에게 유용한 정보를 제공합니다. 

- 요약
    * 그루폰은 프로모션 코드 알림 기능을 구현하면서, 지난 24시간 동안의 성공적인 사용 횟수와 프로모션 코드의 남은 유효 기간을 알림에 표시해야 하는 과제에 직면했습니다.
    * 이를 해결하기 위해 Postgres, Redis, Cassandra 등 다양한 데이터 저장 및 처리 도구를 고려하여 각 도구의 장단점을 분석했습니다. 
    * Postgres는 데이터 정확성은 높지만, 대량의 데이터에 대한 쿼리가 느리다는 단점이 있었습니다. Redis는 간단하고 직관적인 데이터 모델을 제공하지만, 지속적인 저장 기능이 부족했습니다.
    * Cassandra는 고성능과 확장성을 제공하는 분산 데이터베이스로, 시계열 데이터 저장 및 처리에 유용하게 사용될 수 있습니다. 하지만 Cassandra를 사용할 때는 시계열 데이터의 특성에 맞는 최적화가 필요합니다. 
    * 그루폰은 Cassandra의 TTL(Time To Live) 기능과 타임 버킷(Time Bucket) 전략을 활용하여 시계열 데이터 저장 및 처리 문제를 해결했습니다. 
    * Cassandra의 TTL 기능은 데이터의 유효 기간을 설정하고, 타임 버킷 전략은 데이터를 특정 시간 단위로 분할하여 저장함으로써, 데이터 처리 성능을 향상시키고, 데이터 저장 용량을 효율적으로 관리할 수 있도록 했습니다.

- 레퍼런스
    * [Read more](https://medium.com/@aathalye/optimising-cassandra-usage-for-time-series-data-with-learnings-e902878ca350) 

## S3 조건부 쓰기를 이용한 리더 선출

- 소개
    * 분산 시스템에서 여러 노드 중 하나를 리더로 선택하는 리더 선출은 필수적입니다. 
    * 이 글은 S3 조건부 쓰기를 사용하여 리더 선출을 구현하는 간단하고 효율적인 방법을 제시합니다.

- 요약
    * S3 조건부 쓰기는 특정 조건이 만족될 때만 데이터를 저장하는 기능입니다. 이를 활용하여 리더 선출을 구현할 수 있습니다.
    * 리더 역할을 수행할 S3 객체를 생성하고, 각 노드는 S3 객체에 쓰기를 시도합니다. 이때 조건부로 현재 리더 ID가 자신의 ID와 일치하지 않아야 합니다.
    * 쓰기가 성공하면 해당 노드가 새로운 리더가 되고, 실패하면 다른 노드가 이미 리더 역할을 수행하고 있음을 의미합니다.
    * 이 방식은 간단하고 효율적이며, S3의 내구성과 가용성을 활용할 수 있다는 장점이 있습니다.

- 레퍼런스
    * [Read more](https://www.morling.dev/blog/leader-election-with-s3-conditional-writes/) 

## 데이터베이스 성능 향상을 위한 8가지 전략: 종합 가이드

- 소개
    * 소프트웨어가 성장하면서 데이터 저장소의 성능을 향상시켜야 할 필요성이 생기죠. 검색 속도 저하, 쓰기 작업 성능 저하, 전반적인 성능 감소 등의 문제가 발생할 수 있습니다. 이러한 문제점을 이해하는 것만큼 중요한 것은 이를 해결하기 위한 일반적인 접근 방식을 아는 것입니다.
    * 이 글은 데이터베이스 성능 문제 해결에 대한 포괄적인 가이드를 제공하며, 데이터베이스 성능을 개선하기 위해 고려해야 할 8가지 핵심 전략을 다룹니다.

- 요약
    * 이 글에서는 데이터베이스 성능 향상을 위한 8가지 핵심 전략을 살펴봅니다.
    * 먼저 쿼리 최적화를 위한 다양한 기법을 소개합니다. 
    * 인덱싱 전략을 활용하여 데이터베이스 쿼리 속도를 향상시키는 방법을 설명합니다.
    * 데이터베이스 캐싱을 통해 데이터베이스 액세스 시간을 단축하는 방법을 다룹니다.
    * 데이터베이스 튜닝을 통해 데이터베이스 성능을 최적화하는 방법을 자세히 살펴봅니다.
    * 데이터베이스 성능을 모니터링하고 분석하여 문제점을 파악하고 개선하는 방법을 제시합니다.

- 레퍼런스
    * [Read more](https://levelup.gitconnected.com/in-search-of-improving-database-performance-a-comprehensive-guide-with-8-key-strategies-3496f2262cdb) 

## Portmaster: 컨테이너 포트 관리 도구

- 소개
    * 컨테이너 포트 관리를 쉽고 효율적으로 만들어주는 오픈 소스 도구입니다. Docker 컨테이너 포트 충돌을 해결하고, 포트 할당을 자동화하여 개발 및 배포 과정을 간소화할 수 있습니다. 
    * 터미널 명령어 기반으로 사용하기 쉬우며, Docker를 사용하는 개발자, DevOps 엔지니어, 시스템 관리자에게 유용합니다.

- 요약
    * Portmaster는 Docker 컨테이너 포트를 관리하는 데 사용되는 명령줄 도구입니다.
    * 컨테이너 포트 충돌을 해결하고, 포트 할당을 자동화하며, 포트를 사용하는 컨테이너를 표시합니다.
    * 다양한 운영 체제에서 사용 가능하며, GitHub에서 무료로 사용할 수 있습니다.

- 레퍼런스
    * [Read more](https://github.com/safing/portmaster) 

##  [VectorDB] Milvus와 BGE-M3 모델로 문서 임베딩 및 AI 질의응답 구현하기

- 소개
    * Milvus와 BGE-M3 모델을 사용하여 문서를 벡터화하고 Milvus에 저장하는 방법을 소개합니다. 
    * 저장된 데이터를 활용하여 AI 기반 질의응답 시스템을 구축하는 방법까지 상세히 설명합니다. 

- 요약
    * Milvus는 고성능 벡터 데이터베이스로, 대규모 벡터 데이터를 효율적으로 저장하고 검색하는 데 사용됩니다.
    * BGE-M3 모델은 문서 임베딩 작업에 뛰어난 성능을 보이며, AI 질의응답 시스템 구축에 유용합니다.
    * 이 글에서는 Milvus에 문서를 저장하는 과정과 저장된 데이터를 활용하여 질문에 대한 답변을 생성하는 RAG(Retrieval-Augmented Generation) 시스템 구축 방법을 단계별로 설명합니다.
    *  Python 코드를 통해 실제 웹 페이지에서 원하는 정보를 크롤링하는 방법을 이해할 수 있습니다.
    *  Selenium의 기본적인 사용법과 웹 크롤링에 필요한 다양한 기술들을 익힐 수 있습니다.

- 레퍼런스
    * [Read more](https://selfhiam.tistory.com/181)

- 주의
    *  Milvus는 별도의 설치가 필요하며,  본 포스트에서는 docker를 활용한 설치 방법을 다루지 않습니다.
    *  BGE-M3 모델은 GPU 환경에서 더욱 효율적으로 작동하며, CPU 환경에서도 작동하지만 속도 저하가 발생할 수 있습니다.
    *  이 글에서는 Ollama 모델을 사용하여 질의응답 시스템을 구현합니다.  다른 LLM 모델을 사용하려면 해당 모델에 맞는 프롬프트 및 체인 설정이 필요합니다. 

## 주의

 - 이 글은 Gemini Flash를 이용하여 생성한 것으로, 작성하는 도중 일부 정보가 누락되거나 잘못 생성되었을 수 있습니다.

